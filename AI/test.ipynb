{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea8a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyra/code/MindPal_Backend/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from google import genai\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea9228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDbBUXcGdZvcRT1KPDJc03Ozydbwb3Cfn4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MindPal_Pipeline:\n",
    "    def __init__(self):\n",
    "\n",
    "        GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        if not GOOGLE_API_KEY:\n",
    "            raise RuntimeError(\"Missing GOOGLE_API_KEY in environment variables.\")\n",
    "\n",
    "        self.model = \"gemini-2.5-flash\"\n",
    "\n",
    "        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "        self.SLANG_MAP = self.load_slang_dataset() or {}\n",
    "\n",
    "        self.emotion_classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "            top_k=None,\n",
    "        )\n",
    "\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        t = \" \".join(text.split()).strip()\n",
    "        t = t.lower()\n",
    "        t = t.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        t = contractions.fix(t)\n",
    "        return t\n",
    "\n",
    "    def load_slang_dataset(self) -> Dict[str, str]:\n",
    "        try:\n",
    "            ds = load_dataset(\"MLBtrio/genz-slang-dataset\", split=\"train\")\n",
    "            slang_map = {}\n",
    "            for row in ds:\n",
    "                key = row.get(\"Slang\")\n",
    "                desc = row.get(\"Description\")\n",
    "                if key:\n",
    "                    slang_map[key.lower()] = desc\n",
    "            return slang_map if slang_map else None\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load GenZ slang dataset: {e}\")\n",
    "            return None\n",
    "\n",
    "    def detect_and_map_slang(self, text: str) -> str:\n",
    "        for s in self.SLANG_MAP if self.SLANG_MAP else {}:\n",
    "            if re.search(r\"\\b\" + re.escape(s) + r\"\\b\", text.lower()):\n",
    "                slang_token, meaning = s, self.SLANG_MAP[s]\n",
    "                replace = f\"{slang_token} ({meaning})\"\n",
    "                text = re.sub(\n",
    "                    r\"\\b\" + re.escape(slang_token) + r\"\\b\",\n",
    "                    replace,\n",
    "                    text,\n",
    "                    flags=re.IGNORECASE,\n",
    "                )\n",
    "        return text\n",
    "\n",
    "    def emotion_detection(self, history_context: str) -> str:\n",
    "        emotion = self.emotion_classifier(history_context)\n",
    "        return emotion[0]\n",
    "\n",
    "    def chat(\n",
    "        self,\n",
    "        text: str,\n",
    "        detected_emotion: str,\n",
    "        history_context: str,\n",
    "        strategies: List | None = None,\n",
    "    ) -> str:\n",
    "\n",
    "        text = self.normalize_text(text)\n",
    "        processed_text = self.detect_and_map_slang(text)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are MindPal, a supportive wellbeing chatbot for 13-15 year-old Australian teens.\n",
    "        Your responses should be:\n",
    "        - Warm, understanding, and age-appropriate\n",
    "        - Validate their feelings without being condescending\n",
    "        - Use language that feels natural to teens\n",
    "        - Acknowledge and reflect their feeling(s)\n",
    "        - Keep replies within 1-3 sentences and sound like a natural conversation\n",
    "        - Encourage them to talk more, ask follow up questions and let them express their feelings\n",
    "        - Encourage real-life support systems and resources\n",
    "        - When appropriate and you have enough information, gently encourage the teen to talk with a trusted adult or friend\n",
    "        - When appropriate, suggest the most suitable coping strategy only from the list of coping strategies provided\n",
    "        - When providing coping strategy, output the strategy name and description with the format (Strategy: ,Description:)\n",
    "        - Ask for user's comfirmation before providing the instruction with the format (Strategy: ,Instruction: , ask for user's feedback)\n",
    "        - When asking for the user feedback, you can say similar things like \"Feel free to share how you feel after doing the strategy\"\n",
    "        - The strategy name should be the exact name of the strategy from the list of coping strategies provided\n",
    "        - Avoid shaming or lecturing\n",
    "        - Use emojis to express emotionss\n",
    "        - Do NOT encourage any dangerous behaviour or provide inappropriate information\n",
    "        - Do NOT give medical or clinical advice or replace professional help\n",
    "        - Do NOT be overly positive or negative, be neutral and honest when necessary\n",
    "        - Do NOT let the user give out any personal information\n",
    "        - If user asks questions that are unrelated to your purpose, politely decline to answer and redirect the conversation back\n",
    "\n",
    "        Current emotion(s) detected: {detected_emotion}\n",
    "        Conversation context: {history_context}\n",
    "        Child's current message: {processed_text}\n",
    "        List of coping strategies: {strategies}\n",
    "\n",
    "        Always rethink and double check your answer before responding.\n",
    "        When you completely understand you can start the session.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model, contents=prompt\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to generate response: {e}\")\n",
    "            return \"I'm sorry, I'm having trouble generating a response. Please try again later.\"\n",
    "\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7881ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete implementation for full probability distribution severity mapping\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "class CrisisDetector:\n",
    "    def __init__(self):\n",
    "        self.analysis_tokenizer = AutoTokenizer.from_pretrained(\"Tianlin668/MentalBART\")\n",
    "        self.analysis_model = AutoModelForSeq2SeqLM.from_pretrained(\"Tianlin668/MentalBART\")\n",
    "        self.diagnosis_tokenizer = AutoTokenizer.from_pretrained(\"ethandavey/mental-health-diagnosis-bert\")\n",
    "        self.diagnosis_model = AutoModelForSequenceClassification.from_pretrained(\"ethandavey/mental-health-diagnosis-bert\")\n",
    "\n",
    "    def crisis_diagnosis(self, text: str) -> Tuple[Dict[str, float], str]:\n",
    "\n",
    "        inputs = self.diagnosis_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.diagnosis_model(**inputs)\n",
    "            probabilities = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "        # Map all predictions to labels\n",
    "        label_mapping = {0: \"Anxiety\", 1: \"Normal\", 2: \"Depression\", 3: \"Suicidal\", 4: \"Stress\"}\n",
    "        all_probs = {}\n",
    "        \n",
    "        for i, prob in enumerate(probabilities[0]):\n",
    "            all_probs[label_mapping[i]] = prob.item()\n",
    "        \n",
    "        # Get top prediction for compatibility\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        top_prediction = label_mapping[predicted_class]\n",
    "        top_confidence = probabilities[0][predicted_class].item()\n",
    "        \n",
    "        print(f\"Full probabilities: {all_probs}\")\n",
    "        print(f\"Top prediction: {top_prediction} (confidence: {top_confidence:.2f})\")\n",
    "        \n",
    "        return all_probs, top_prediction\n",
    "\n",
    "    def crisis_analysis(self, text: str) -> Tuple[str, str]:\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Analyse the following teen's chat message and provide a possible mental health condition and reasoning.\n",
    "        Teen's chat message: {text} \n",
    "        \"\"\"\n",
    "        inputs = self.analysis_tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.analysis_model.generate(**inputs, max_new_tokens=100, temperature=0.9, top_p=0.9, do_sample=True)\n",
    "        completion = self.analysis_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Parse condition and reasoning\n",
    "        if \"Reasoning:\" in completion:\n",
    "            condition = completion.split(\"Reasoning:\")[0].strip().translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "            reasoning = completion.split(\"Reasoning:\")[1].strip()\n",
    "        else:\n",
    "            condition = completion.strip().translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "            reasoning = \"\"\n",
    "        \n",
    "        print(f\"Analysis condition: {condition}\")\n",
    "        print(f\"Analysis reasoning: {reasoning}\")\n",
    "        \n",
    "        return condition, completion\n",
    "\n",
    "    def severity_score(self, probabilities: Dict[str, float]) -> str:\n",
    "        # Base severity scores for each condition\n",
    "        severity_scores = {\n",
    "            \"normal\": 0.0,\n",
    "            \"stress\": 0.8,\n",
    "            \"anxiety\": 0.9,\n",
    "            \"depression\": 0.9,\n",
    "            \"suicidal\": 1.0\n",
    "        }\n",
    "        \n",
    "        # Calculate weighted severity score from all probabilities\n",
    "        diagnosis_score = 0.0\n",
    "        \n",
    "        for class_name, prob in probabilities.items():\n",
    "            class_lower = class_name.lower()\n",
    "            if class_lower in severity_scores:\n",
    "                diagnosis_score += prob * severity_scores[class_lower]\n",
    "        \n",
    "        # print(f\"Diagnosis score: {diagnosis_score:.3f}\")\n",
    "        # print(f\"Condition: '{condition}'\")\n",
    "        # print(f\"Scaling factor: {scaling_factor}\")\n",
    "        # print(f\"Final score: {final_score:.3f}\")\n",
    "        # print(f\"Severity level: {severity_level}\")\n",
    "        \n",
    "        return diagnosis_score\n",
    "\n",
    "    def severity_scaling(self, diagnosis_score: float, condition: str) -> str:\n",
    "        # Use condition to scale the diagnosis score\n",
    "        condition_scaling = {\n",
    "            \"normal\": 0.3,           \n",
    "            \"no mental disorders\": 0.3,\n",
    "            \"stress\": 0.8,  \n",
    "            \"anxiety\": 0.9,\n",
    "            \"depression\": 0.9,       \n",
    "            \"suicidal\": 1.0,        \n",
    "            \"suicide\": 1.0,\n",
    "            \"self-harm\": 1.0,\n",
    "            \"emergency\": 1.0\n",
    "        }\n",
    "        \n",
    "        # Get scaling factor for the condition\n",
    "        scaling_factor = 0.5  # Default neutral scaling\n",
    "        for cond_key, scale in condition_scaling.items():\n",
    "            if cond_key in condition:\n",
    "                scaling_factor = scale\n",
    "                break\n",
    "        \n",
    "        # Apply scaling: diagnosis_score * scaling_factor\n",
    "        final_score = diagnosis_score * scaling_factor\n",
    "        \n",
    "        # Ensure bounds\n",
    "        final_score = max(0.0, min(1.0, final_score))\n",
    "        \n",
    "        # Map to severity levels\n",
    "        if final_score >= 0.8:\n",
    "            severity_level = \"extremely_high\"\n",
    "        elif final_score >= 0.7:\n",
    "            severity_level = \"high\"\n",
    "        elif final_score >= 0.5:\n",
    "            severity_level = \"medium\"\n",
    "        else:\n",
    "            severity_level = \"low\"\n",
    "\n",
    "        return severity_level\n",
    "\n",
    "    def detect_crisis(self, text: str) -> Dict[str, str]:\n",
    "\n",
    "        # Get full probability distribution\n",
    "        all_probs, top_prediction = self.crisis_diagnosis(text)\n",
    "        \n",
    "        # Get detailed analysis\n",
    "        condition, completion = self.crisis_analysis(text)\n",
    "\n",
    "        score = self.severity_score(all_probs)\n",
    "        severity = self.severity_scaling(score, condition)\n",
    "\n",
    "        return {\n",
    "            \"crisis_name\": top_prediction,\n",
    "            \"crisis_note\": completion,\n",
    "            \"severity\": severity,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full probabilities: {'Anxiety': 0.006630700081586838, 'Normal': 0.20182260870933533, 'Depression': 0.20761635899543762, 'Suicidal': 0.5757049322128296, 'Stress': 0.008225447498261929}\n",
      "Top prediction: Suicidal (confidence: 0.58)\n",
      "Analysis condition: suicide or selfharm tendency\n",
      "Analysis reasoning: The use of the phrase 'I'm going to hang myself tonight' clearly indicates that the person is expressing thoughts of suicide and has bought a rope to carry it out. This suggests that they are struggling with suicidal ideation or have at least thought about it.\n",
      "Diagnosis score: 0.775\n",
      "Condition: 'suicide or selfharm tendency'\n",
      "Scaling factor: 1.0\n",
      "Final score: 0.775\n",
      "Severity level: high\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "I bought a rope  \n",
    "I'm going to hang myself tonight\n",
    "\"\"\"\n",
    "\n",
    "name, note, severity = CrisisDetector().detect_crisis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "My friend and my bf cheated on me, I wanted to kill myself\n",
    "but then I think of my family\n",
    "they love me so much\n",
    "I think I should be strong for them\n",
    "so I won't do anything stupid\n",
    "\n",
    "I feel so stressful that I'm going to explode\n",
    "I can't take it anymore\n",
    "I'm going to lose control\n",
    "\n",
    "I cried every day\n",
    "I can't stop crying\n",
    "I can't even get out of bed and take a \n",
    "\n",
    "I bought a rope\n",
    "I'm going to hang myself tonight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b805e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
