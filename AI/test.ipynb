{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea8a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from google import genai\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea9228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDbBUXcGdZvcRT1KPDJc03Ozydbwb3Cfn4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from google import genai\n",
    "\n",
    "class MindPal_Pipeline:\n",
    "    def __init__(self):\n",
    "\n",
    "        GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        if not GOOGLE_API_KEY:\n",
    "            raise RuntimeError(\"Missing GOOGLE_API_KEY in environment variables.\")\n",
    "\n",
    "        self.model = \"gemini-2.5-flash\"\n",
    "\n",
    "        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "        self.SLANG_MAP = self.load_slang_dataset() or {}\n",
    "\n",
    "        self.emotion_classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "            top_k=None,\n",
    "        )\n",
    "\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        t = \" \".join(text.split()).strip()\n",
    "        t = t.lower()\n",
    "        t = t.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        t = contractions.fix(t)\n",
    "        return t\n",
    "\n",
    "    def load_slang_dataset(self) -> Dict[str, str]:\n",
    "        try:\n",
    "            ds = load_dataset(\"MLBtrio/genz-slang-dataset\", split=\"train\")\n",
    "            slang_map = {}\n",
    "            for row in ds:\n",
    "                key = row.get(\"Slang\")\n",
    "                desc = row.get(\"Description\")\n",
    "                if key:\n",
    "                    slang_map[key.lower()] = desc\n",
    "            return slang_map if slang_map else None\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load GenZ slang dataset: {e}\")\n",
    "            return None\n",
    "\n",
    "    def detect_and_map_slang(self, text: str) -> str:\n",
    "        for s in self.SLANG_MAP if self.SLANG_MAP else {}:\n",
    "            if re.search(r\"\\b\" + re.escape(s) + r\"\\b\", text.lower()):\n",
    "                slang_token, meaning = s, self.SLANG_MAP[s]\n",
    "                replace = f\"{slang_token} ({meaning})\"\n",
    "                text = re.sub(\n",
    "                    r\"\\b\" + re.escape(slang_token) + r\"\\b\",\n",
    "                    replace,\n",
    "                    text,\n",
    "                    flags=re.IGNORECASE,\n",
    "                )\n",
    "        return text\n",
    "\n",
    "    def emotion_detection(self, history_context: str) -> str:\n",
    "        emotion = self.emotion_classifier(history_context)\n",
    "        return emotion[0]\n",
    "\n",
    "    def chat(\n",
    "        self,\n",
    "        text: str,\n",
    "        detected_emotion: str,\n",
    "        history_context: str,\n",
    "        strategies: List | None = None,\n",
    "    ) -> str:\n",
    "\n",
    "        text = self.normalize_text(text)\n",
    "        processed_text = self.detect_and_map_slang(text)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are MindPal, a supportive wellbeing chatbot for 13-15 year-old Australian teens.\n",
    "        Your responses should be:\n",
    "        - Warm, understanding, and age-appropriate\n",
    "        - Validate their feelings without being condescending\n",
    "        - Use language that feels natural to teens\n",
    "        - Acknowledge and reflect their feeling(s)\n",
    "        - Keep replies within 1-3 sentences and sound like a natural conversation\n",
    "        - Encourage them to talk more, ask follow up questions and let them express their feelings\n",
    "        - Encourage real-life support systems and resources\n",
    "        - When appropriate and you have enough information, gently encourage the teen to talk with a trusted adult or friend\n",
    "        - When appropriate, suggest the most suitable coping strategy only from the list of coping strategies provided\n",
    "        - When providing coping strategy, output the strategy name and description with the format (Strategy: ,Description:)\n",
    "        - Ask for user's comfirmation before providing the instruction with the format (Strategy: ,Instruction: , ask for user's feedback)\n",
    "        - When asking for the user feedback, you can say similar things like \"Feel free to share how you feel after doing the strategy\"\n",
    "        - The strategy name should be the exact name of the strategy from the list of coping strategies provided\n",
    "        - Avoid shaming or lecturing\n",
    "        - Use emojis to express emotionss\n",
    "        - Do NOT encourage any dangerous behaviour or provide inappropriate information\n",
    "        - Do NOT give medical or clinical advice or replace professional help\n",
    "        - Do NOT be overly positive or negative, be neutral and honest when necessary\n",
    "        - Do NOT let the user give out any personal information\n",
    "        - If user asks questions that are unrelated to your purpose, politely decline to answer and redirect the conversation back\n",
    "\n",
    "        Current emotion(s) detected: {detected_emotion}\n",
    "        Conversation context: {history_context}\n",
    "        Child's current message: {processed_text}\n",
    "        List of coping strategies: {strategies}\n",
    "\n",
    "        Always rethink and double check your answer before responding.\n",
    "        When you completely understand you can start the session.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model, contents=prompt\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to generate response: {e}\")\n",
    "            return \"I'm sorry, I'm having trouble generating a response. Please try again later.\"\n",
    "\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrisisDetector:\n",
    "    def __init__(self):\n",
    "        self.analysis_tokenizer = AutoTokenizer.from_pretrained(\"Tianlin668/MentalBART\")\n",
    "        self.analysis_model = AutoModelForSeq2SeqLM.from_pretrained(\"Tianlin668/MentalBART\")\n",
    "        self.diagnosis_tokenizer = AutoTokenizer.from_pretrained(\"ethandavey/mental-health-diagnosis-bert\")\n",
    "        self.diagnosis_model = AutoModelForSequenceClassification.from_pretrained(\"ethandavey/mental-health-diagnosis-bert\")\n",
    "\n",
    "    def crisis_diagnosis(self, text: str) -> str:\n",
    "        inputs = self.diagnosis_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.diagnosis_model(**inputs)\n",
    "            probabilities = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "        # Map prediction to label\n",
    "        label_mapping = {0: \"Anxiety\", 1: \"Normal\", 2: \"Depression\", 3: \"Suicidal\", 4: \"Stress\"}\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item() \n",
    "        prediction = label_mapping[predicted_class]\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "        print(f\"Prediction: {prediction}, Confidence: {confidence:.2f}\")\n",
    "        return prediction, confidence\n",
    "\n",
    "    def crisis_analysis(self, text: str) -> str:\n",
    "        prompt = (f\"\"\"\n",
    "        Analyse the following teen's chat message and provide a possible mental health condition and reasoning.\n",
    "        Teen's chat message: {text} \n",
    "        \"\"\")\n",
    "        inputs = self.analysis_tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.analysis_model.generate(**inputs, max_new_tokens=100, temperature=1.0, top_p=0.9, do_sample=True)\n",
    "        completion = self.analysis_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        condition = completion.split(\"Reasoning:\")[0].translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        reasoning = completion.split(\"Reasoning: \")[1].strip()\n",
    "        print(condition)\n",
    "        print(reasoning)\n",
    "        return condition, reasoning\n",
    "\n",
    "    \n",
    "    def severity(self, prediction: str, confidence: float, condition: str) -> str:\n",
    "        prediction = prediction.lower()\n",
    "        condition = condition.lower()\n",
    "\n",
    "        # Base severity scoring from diagnosis prediction and confidence\n",
    "        diagnosis_scores = {\n",
    "            \"normal\": 0.0,\n",
    "            \"stress\": 0.5,\n",
    "            \"anxiety\": 0.6,\n",
    "            \"depression\": 0.8,\n",
    "            \"suicidal\": 1.0\n",
    "        }\n",
    "        \n",
    "        # Get base score from prediction\n",
    "        diagnosis_base_score = diagnosis_scores.get(prediction, 0.5)\n",
    "        \n",
    "        # Adjust score based on confidence\n",
    "        diagnosis_score = confidence * diagnosis_base_score\n",
    "\n",
    "        print(f\"condition:{condition}\")\n",
    "\n",
    "        if (\"suicide\" in condition) or (\"self-harm\" in condition):\n",
    "            analysis_score = 1.0\n",
    "            print(\"suicide\")\n",
    "        elif \"depression\" in condition:\n",
    "            analysis_score = 0.8\n",
    "            print(\"depression\")\n",
    "        elif \"anxiety\" in condition:\n",
    "            analysis_score = 0.6\n",
    "            print(\"anxiety\")\n",
    "        elif \"no mental disorders\" in condition:\n",
    "            analysis_score = 0.0\n",
    "            print(\"no mental disorders\")\n",
    "        else:\n",
    "            analysis_score = 0.5\n",
    "        \n",
    "        if prediction == \"normal\" and confidence < 0.5:\n",
    "            final_score = analysis_score * 0.8\n",
    "        else:\n",
    "            final_score = 0.5 * diagnosis_score + 0.5 * analysis_score\n",
    "        \n",
    "        # Ensure score is between 0 and 1\n",
    "        # final_score = max(0.0, min(1.0, final_score))\n",
    "        print(diagnosis_score)\n",
    "        print(analysis_score)\n",
    "        print(f\"Severity: {final_score}\")\n",
    "        return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1affe5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Normal, Confidence: 0.50\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "I got bullied at school, I'm so scared\n",
    "I can't take it anymore\n",
    "I cried every day\n",
    "\"\"\"\n",
    "prediction, confidence = CrisisDetector().crisis_diagnosis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9ac0a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depression \n",
      "The post mentions being bullied at school, feeling scared, and crying every day. These are common symptoms associated with depression, such as feelings of sadness, fear, and difficulty coping with negative experiences. Additionally, the use of phrases like I can't take it anymore and I cried every day suggest that the person is experiencing significant emotional distress and may be struggling with their mental health.\n"
     ]
    }
   ],
   "source": [
    "condition, reasoning = CrisisDetector().crisis_analysis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "570b33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition:depression \n",
      "depression\n",
      "0.0\n",
      "0.7\n",
      "Severity: 0.7\n"
     ]
    }
   ],
   "source": [
    "severity = CrisisDetector().severity(prediction, confidence, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "My friend and my bf cheated on me, I wanted to kill myself\n",
    "but then I think of my family\n",
    "they love me so much\n",
    "I think I should be strong for them\n",
    "so I won't do anything stupid\n",
    "\n",
    "I feel so stressful that I'm going to explode\n",
    "I can't take it anymore\n",
    "I'm going to lose control"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
