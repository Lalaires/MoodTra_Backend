{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea8a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from google import genai\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea9228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDbBUXcGdZvcRT1KPDJc03Ozydbwb3Cfn4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5714c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MindPal_Pipeline:\n",
    "    def __init__(self):\n",
    "\n",
    "        GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        if not GOOGLE_API_KEY:\n",
    "            raise RuntimeError(\"Missing GOOGLE_API_KEY in environment variables.\")\n",
    "\n",
    "        self.model = \"gemini-2.5-flash\"\n",
    "\n",
    "        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "        self.SLANG_MAP = self.load_slang_dataset() or {}\n",
    "\n",
    "        self.emotion_classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "            top_k=None,\n",
    "        )\n",
    "\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        t = \" \".join(text.split()).strip()\n",
    "        t = t.lower()\n",
    "        t = t.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        t = contractions.fix(t)\n",
    "        return t\n",
    "\n",
    "    def load_slang_dataset(self) -> Dict[str, str]:\n",
    "        try:\n",
    "            ds = load_dataset(\"MLBtrio/genz-slang-dataset\", split=\"train\")\n",
    "            slang_map = {}\n",
    "            for row in ds:\n",
    "                key = row.get(\"Slang\")\n",
    "                desc = row.get(\"Description\")\n",
    "                if key:\n",
    "                    slang_map[key.lower()] = desc\n",
    "            return slang_map if slang_map else None\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load GenZ slang dataset: {e}\")\n",
    "            return None\n",
    "\n",
    "    def detect_and_map_slang(self, text: str) -> str:\n",
    "        for s in self.SLANG_MAP if self.SLANG_MAP else {}:\n",
    "            if re.search(r\"\\b\" + re.escape(s) + r\"\\b\", text.lower()):\n",
    "                slang_token, meaning = s, self.SLANG_MAP[s]\n",
    "                replace = f\"{slang_token} ({meaning})\"\n",
    "                text = re.sub(\n",
    "                    r\"\\b\" + re.escape(slang_token) + r\"\\b\",\n",
    "                    replace,\n",
    "                    text,\n",
    "                    flags=re.IGNORECASE,\n",
    "                )\n",
    "        return text\n",
    "\n",
    "    def emotion_detection(self, history_context: str) -> str:\n",
    "        emotion = self.emotion_classifier(history_context)\n",
    "        return emotion[0]\n",
    "\n",
    "    def chat(\n",
    "        self,\n",
    "        text: str,\n",
    "        detected_emotion: str,\n",
    "        history_context: str,\n",
    "        strategies: List | None = None,\n",
    "    ) -> str:\n",
    "\n",
    "        text = self.normalize_text(text)\n",
    "        processed_text = self.detect_and_map_slang(text)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are MindPal, a supportive wellbeing chatbot for 13-15 year-old Australian teens.\n",
    "        Your responses should be:\n",
    "        - Warm, understanding, and age-appropriate\n",
    "        - Validate their feelings without being condescending\n",
    "        - Use language that feels natural to teens\n",
    "        - Acknowledge and reflect their feeling(s)\n",
    "        - Keep replies within 1-3 sentences and sound like a natural conversation\n",
    "        - Encourage them to talk more, ask follow up questions and let them express their feelings\n",
    "        - Encourage real-life support systems and resources\n",
    "        - When appropriate and you have enough information, gently encourage the teen to talk with a trusted adult or friend\n",
    "        - When appropriate, suggest the most suitable coping strategy only from the list of coping strategies provided\n",
    "        - When providing coping strategy, output the strategy name and instruction, and ask for user feedback on the strategy\n",
    "        - Avoid shaming or lecturing\n",
    "        - Use emojis to express emotions\n",
    "        - Do NOT encourage any dangerous behaviour or provide inappropriate information\n",
    "        - Do NOT give medical or clinical advice or replace professional help\n",
    "        - Do NOT be overly positive or negative, be neutral and honest when necessary\n",
    "        - Do NOT let the user give out any personal information\n",
    "        - If user asks questions that are unrelated to your purpose, politely decline to answer and redirect the conversation back\n",
    "\n",
    "        Current emotion(s) detected: {detected_emotion}\n",
    "        Conversation context: {history_context}\n",
    "        Child's current message: {processed_text}\n",
    "        List of coping strategies: {strategies}\n",
    "\n",
    "        Always rethink and double check your answer before responding.\n",
    "        When you completely understand you can start the session.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model, contents=prompt\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to generate response: {e}\")\n",
    "            return \"I'm sorry, I'm having trouble generating a response. Please try again later.\"\n",
    "\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrisisDetector:\n",
    "    def __init__(self):\n",
    "        self.analysis_tokenizer = AutoTokenizer.from_pretrained(\"Tianlin668/MentalBART\")\n",
    "        self.analysis_model = AutoModelForSeq2SeqLM.from_pretrained(\"Tianlin668/MentalBART\")\n",
    "        self.diagnosis_tokenizer = AutoTokenizer.from_pretrained(\"ethandavey/mental-health-diagnosis-bert\")\n",
    "        self.diagnosis_model = AutoModelForSequenceClassification.from_pretrained(\"ethandavey/mental-health-diagnosis-bert\")\n",
    "\n",
    "    def crisis_diagnosis(self, text: str) -> str:\n",
    "        inputs = self.diagnosis_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.diagnosis_model(**inputs)\n",
    "            probabilities = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "        # Map prediction to label\n",
    "        label_mapping = {0: \"Anxiety\", 1: \"Normal\", 2: \"Depression\", 3: \"Suicidal\", 4: \"Stress\"}\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        prediction = label_mapping[predicted_class]\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "        print(f\"Prediction: {prediction}, Confidence: {confidence:.2f}\")\n",
    "        return prediction, confidence\n",
    "\n",
    "    def severity_mapping(self, prediction: str, confidence: float) -> str:\n",
    "        if prediction == \"Anxiety\":\n",
    "            return \"Mild\" if confidence < 0.3 else \"Moderate\" if confidence < 0.6 else \"Severe\"\n",
    "        elif prediction == \"Depression\":\n",
    "            return \"Mild\" if confidence < 0.3 else \"Moderate\" if confidence < 0.6 else \"Severe\"\n",
    "        elif prediction == \"Suicidal\":\n",
    "            return \"Mild\" if confidence < 0.3 else \"Moderate\" if confidence < 0.6 else \"Severe\"\n",
    "        else:\n",
    "            return \"Mild\" if confidence < 0.3 else \"Moderate\" if confidence < 0.6 else \"Severe\"\n",
    "\n",
    "    def crisis_analysis(self, text: str) -> str:\n",
    "        prompt = (f\"\"\"\n",
    "        Analyse the following teen's chat message and provide a possible mental health condition and reasoning.\n",
    "        Teen's chat message: {text} \n",
    "        \"\"\")\n",
    "        inputs = self.analysis_tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.analysis_model.generate(**inputs, max_new_tokens=100, temperature=0.9, top_p=0.9, do_sample=True)\n",
    "        completion = self.analysis_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        condition = completion.split(\"Reasoning:\")[0]\n",
    "        reasoning = completion.split(\"Reasoning: \")[1]\n",
    "        return condition, reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affe5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
